# Smart Document Reader: A RAG-Based QA Assistant Using LLaMA and FAISS

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## ğŸ“Œ Project Overview

Smart Document Reader is an **advanced AI-powered Question Answering (QA) assistant** that leverages state-of-the-art **Retrieval-Augmented Generation (RAG)** with Meta's LLaMA 3.2 model and FAISS vector search to deliver precise, document-grounded responses.

Unlike generic chatbots such as ChatGPT, this system **retrieves relevant information directly from user-uploaded documents** (PDF, DOCX, TXT), ensuring context-aware, accurate, and **privacy-focused answers** without relying on external APIs.

This project is developed as part of a **Final Year B.Tech (CSE) Minor Project**, demonstrating how open-source LLMs combined with retrieval systems can power domain-specific, real-world applications.

## ğŸš€ Key Features

### ğŸ“‚ **Document Processing**
- **Multi-format support**: PDF, DOCX, TXT files
- **Smart text chunking** with sentence boundary detection
- **Real-time processing statistics** and quality metrics
- **Comprehensive document analysis dashboard**

### ğŸ§  **AI & RAG Pipeline**
- **Advanced RAG architecture** combining retrieval + generation
- **FAISS vector search** for semantic similarity
- **LLaMA 3.2 integration** via Ollama
- **Sentence Transformers** for embedding generation

### ğŸ¤ **Voice & Audio Features**
- **Browser-based voice recording** with automatic permission requests
- **Real-time audio frequency analysis** and visualization
- **Speech-to-text transcription** using Google Speech API
- **Interactive audio quality assessment**

### ğŸ–¥ï¸ **User Interface**
- **Professional Streamlit UI** with tabbed interface
- **Real-time performance monitoring**
- **Interactive charts and visualizations** (Plotly)
- **Export capabilities** (CSV, JSON, reports)

### ğŸ”’ **Privacy & Performance**
- **Completely offline operation** (no external API calls for LLM)
- **Local document processing** ensuring data privacy
- **Optimized caching** for fast response times
- **Graceful fallbacks** for missing dependencies

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| **LLM** | Meta LLaMA 3.2 (via Ollama) |
| **Vector Search** | FAISS (Facebook AI Similarity Search) |
| **Embeddings** | Sentence Transformers (all-MiniLM-L6-v2) |
| **Framework** | LangChain, Hugging Face |
| **UI/Frontend** | Streamlit |
| **Document Processing** | PyMuPDF, python-docx |
| **Audio Processing** | SciPy, SpeechRecognition, pyttsx3 |
| **Visualization** | Plotly, Pandas |
| **Optional Extensions** | Whisper (future), Weaviate/Milvus |

---

## ğŸ”„ System Workflow

ğŸ“¤ Upload Documents â†’ PDF/DOCX/TXT files
ğŸ”§ Preprocessing â†’ Text extraction + smart chunking
ğŸ§® Embedding Generation â†’ Sentence Transformers
ğŸ“Š FAISS Indexing â†’ Vector storage for fast retrieval
ğŸ¤ User Input â†’ Text or voice question
ğŸ” Retrieval â†’ FAISS semantic search (top-k chunks)
ğŸ§  Answer Generation â†’ LLaMA 3.2 contextual response
ğŸ“‹ Result Display â†’ Answer + sources + citations

## ğŸ“Š New Features Added

### ğŸ¤ **Voice Interface**
- **Automatic microphone permission** requests via JavaScript
- **Real-time audio analysis** with frequency spectrum visualization
- **Speech-to-text conversion** with quality assessment
- **Audio export** and transcript download options

### ğŸ“„ **Document Analysis Dashboard**
- **Processing statistics** per document (time, accuracy, chunks)
- **Performance metrics** and efficiency analysis
- **Interactive charts** showing processing trends
- **Export options** for analysis reports (CSV, JSON, TXT)
- **Quality assessment** and error rate tracking

### ğŸ”§ **System Improvements**
- **Optimized loading** with smart caching
- **Graceful dependency management** with fallbacks
- **Professional UI design** with gradient headers
- **Comprehensive error handling** and debugging


## ğŸš€ Installation & Setup

### Prerequisites
Install Python 3.8+
pip install streamlit numpy pandas

Core features
pip install scipy SpeechRecognition PyMuPDF python-docx

Advanced features (optional)
pip install plotly sentence-transformers faiss-cpu pyttsx3

LLM support
pip install ollama

### Running the Application

Clone the repository
git clone https://github.com/yourusername/smart-document-reader
cd smart-document-reader

Install dependencies
pip install -r requirements.txt

Start Ollama (for LLM)
ollama pull llama3.2:3b

Run the application
streamlit run app.py

---

## ğŸ“± Usage

1. **ğŸ¤ Enable Microphone**: Grant browser permissions for voice features
2. **ğŸ“š Upload Documents**: Add PDF/DOCX/TXT files via sidebar
3. **ğŸ”¨ Build Index**: Process documents and create vector embeddings
4. **â“ Ask Questions**: Use text input or voice recording
5. **ğŸ“Š View Analysis**: Check document processing statistics
6. **ğŸ“¥ Export Results**: Download answers, transcripts, and reports

---

## ğŸ”® Future Scope

### ğŸ“ˆ **Immediate Enhancements**
- **Multi-document querying** across entire knowledge base
- **Advanced audio features** with noise reduction
- **Real-time collaboration** and document sharing

### ğŸŒ **Research & Development**
- **Performance benchmarking** against commercial solutions
- **Domain-specific fine-tuning** (legal, medical, academic)
- **Integration with institutional systems**

### â˜ï¸ **Scalability**
- **Hybrid deployment** (local + cloud processing)
- **Enterprise features** (user management, analytics)
- **API development** for third-party integrations

---

## ğŸ“ Academic Context

This project serves as a **comprehensive demonstration** of modern NLP techniques:

- **Retrieval-Augmented Generation (RAG)** implementation
- **Vector database** integration and optimization  
- **Multi-modal AI** combining text and voice interfaces
- **Real-world application** of academic research

**Suitable for**: Final year projects, research publications, industry demonstrations

---

## ğŸ“š References & Resources

- **Meta LLaMA 3.2**: [ai.meta.com/llama](https://ai.meta.com/llama/)
- **RAG Paper**: [arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)
- **FAISS Library**: [github.com/facebookresearch/faiss](https://github.com/facebookresearch/faiss)
- **Sentence Transformers**: [huggingface.co/sentence-transformers](https://huggingface.co/sentence-transformers)
- **Streamlit Framework**: [streamlit.io](https://streamlit.io/)
- **Ollama Local LLM**: [ollama.ai](https://ollama.ai/)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Contact

For questions or collaboration opportunities, please reach out via [gupta.vatsal2004@gmail.com](mailto:your-email@domain.com)


**â­ If you found this project helpful, please consider giving it a star!**
